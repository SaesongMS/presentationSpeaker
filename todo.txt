- read from json:
{
  "slides": [
    {
        "title": "Slide 1",
        "content": "Content 1",
        "duration": 5
    },
    {
        "title": "Slide 2",
        "content": "Content 2",
        "duration": 10
    }
  ]
}

or

{
  "slides": [
    {
        "title": "Slide 1",
        "text1": "Content 1",
        "text2": "Content 2",
        "duration": 5
    },
    {
        "title": "Slide 2",
        "text1": "Content 2",
        "text2": "Content 2",,
        "text3": "Content 2",
        "duration": 5
    }
  ]
}
- zapis na dysku i dopisywanie sciezki do jsona
- dzielenie na czesci, zeby zawsze generowalo calosc (https://github.com/suno-ai/bark/blob/main/notebooks/long_form_generation.ipynb) ✅

Robienie wideo:
- ekstrakcja każdej strony z pdfa jako obrazek 
(https://github.com/Belval/pdf2image)
- łączenie zdjęć z wideo
(Myślę że warto użyć ffmpeg, nawet release I wywoływać go konsolową komenda systemową ze skryptu pythonowego, ale biblioteka pewnie też działa)

Front:
- pytanie czy robimy cli czy GUI
- jak gui to trzeba zrobić research 
- myślę że w takim wypadku dobrze by było zrobić release, w sensie wszystkie potrzebne biblioteki i program skompilować w jeden exec

Działanie frontu:
- załączenie jsona i pdfa
- wybranie speakera
- generacja wszystkich slajdów albo wybranych, z możliwością ponownej generaci wybranego slajdu
- generacja filmu (slajdy+dźwięk)
